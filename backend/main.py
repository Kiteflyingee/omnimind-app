import os
import json
import asyncio
from typing import List, Optional
from fastapi import FastAPI, Request, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import openai
from dotenv import load_dotenv

from config_loader import load_config
from db import DBService
from formula import FormulaService
from memory_service import MemoryService
from logger import get_logger

logger = get_logger("Main")

# Load environment variables from .env.local
base_dir = os.path.dirname(os.path.abspath(__file__))
dotenv_path = os.path.join(base_dir, "..", ".env.local")
load_dotenv(dotenv_path=dotenv_path)

app = FastAPI()

# Add CORS Middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
config = load_config()
db_service = DBService(os.path.abspath(os.path.join(base_dir, "..", config["storage"]["sqlite_path"])))
formula_service = FormulaService(
    config["models"]["advanced"]["base_url"],
    config["models"]["advanced"]["api_key"],
    db_service
)
memory_service = MemoryService(config["memory"]["mem0"]["api_key"])

class LoginRequest(BaseModel):
    username: str

class ChatRequest(BaseModel):
    message: str
    sessionId: str
    userId: str
    image: Optional[str] = None
    reasoning: Optional[bool] = False
    useMemory: Optional[bool] = True
    recentContextCount: Optional[int] = 20  # -1 = unlimited, 0 = none

async def summarize_session_title(session_id: str, user_msg: str, ai_msg: str):
    try:
        fast_client = openai.AsyncOpenAI(
            api_key=config["models"]["fast"]["api_key"],
            base_url=config["models"]["fast"]["base_url"]
        )
        prompt = f"è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œæ€»ç»“ä¸€ä¸ªç®€çŸ­çš„ä¼šè¯æ ‡é¢˜ï¼ˆä¸è¶…è¿‡6ä¸ªå­—ï¼‰ã€‚åªè¿”å›æ ‡é¢˜æ–‡å­—ï¼Œä¸è¦æœ‰ä»»ä½•ä¿®é¥°è¯­æˆ–æ ‡ç‚¹ã€‚\n\nç”¨æˆ·: {user_msg}\nåŠ©æ‰‹: {ai_msg}"
        
        response = await fast_client.chat.completions.create(
            model=config["models"]["fast"]["name"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=30
        )
        new_title = response.choices[0].message.content.strip().replace("â€œ", "").replace("â€", "").replace("æ ‡é¢˜ï¼š", "")
        if new_title:
            db_service.update_session_title(session_id, new_title)
            return new_title
    except Exception as e:
        logger.warning(f"Failed to summarize title: {e}")
    return None

# Context Safety: Token estimation and history compression
MAX_HISTORY_TOKENS = config.get("context", {}).get("max_history_tokens", 200000)

def estimate_tokens(messages: list) -> int:
    """Rough token estimation for mixed Chinese/English text (~2 chars per token)"""
    total = 0
    for m in messages:
        content = m.get("content") or ""
        if isinstance(content, str):
            total += len(content) // 2
        elif isinstance(content, list):  # Multi-modal content
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    total += len(item.get("text", "")) // 2
    return total

async def generate_history_summary(history: list) -> str:
    """Generate a summary of conversation history using fast model"""
    try:
        fast_client = openai.AsyncOpenAI(
            api_key=config["models"]["fast"]["api_key"],
            base_url=config["models"]["fast"]["base_url"]
        )
        
        # Format history for summarization
        formatted = []
        for m in history:
            role = "ç”¨æˆ·" if m["role"] == "user" else "åŠ©æ‰‹"
            content = m.get("content") or ""
            if isinstance(content, str) and content.strip():
                formatted.append(f"{role}: {content[:500]}")  # Truncate long messages
        
        history_text = "\n".join(formatted[-50:])  # Last 50 messages max for summarization
        
        prompt = f"è¯·å¯¹ä»¥ä¸‹å¯¹è¯å†å²è¿›è¡Œç®€æ´æ‘˜è¦ï¼Œä¿ç•™å…³é”®ä¿¡æ¯ã€ç”¨æˆ·åå¥½å’Œé‡è¦ç»“è®ºã€‚æ‘˜è¦åº”åœ¨500å­—ä»¥å†…ã€‚\n\n{history_text}"
        
        response = await fast_client.chat.completions.create(
            model=config["models"]["fast"]["name"],
            messages=[{"role": "user", "content": prompt}],
            max_tokens=800
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Failed to generate history summary: {e}")
        return "å†å²å¯¹è¯æ‘˜è¦ç”Ÿæˆå¤±è´¥"

@app.post("/chat")
async def chat(request: ChatRequest):
    async def event_generator():
        try:
            # Yield initial padding to bypass potential proxy buffering (e.g. Nginx, Cloudflare)
            # This is ignored by the frontend parser as currentMode is null.
            yield " " * 1024 + "\n"
            
            # 1. Retrieve memories and hard rules (Isolated by sessionId)
            memories = ""
            if request.useMemory:
                yield "s:ğŸ” æ­£åœ¨æ£€ç´¢è®°å¿†ä¸è§„åˆ™..."
                # Run sync search in thread to avoid blocking event loop
                memories = await asyncio.to_thread(
                    memory_service.search_memory, 
                    request.message, 
                    request.userId, 
                    request.sessionId
                )
            else:
                yield "s:ğŸ” æ­£åœ¨æ£€ç´¢è§„åˆ™..."
            
            # Run sync DB calls in threads
            hard_rules_list = await asyncio.to_thread(
                db_service.get_hard_rules,
                request.userId,
                request.sessionId
            )
            hard_rules_str = "\n".join([f"- {r['content']}" for r in hard_rules_list]) if hard_rules_list else "æš‚æ— æœ¬ä¼šè¯ä¸“æœ‰çš„ç¡¬æ€§è§„åˆ™"
            
            # 2. Prepare context
            system_prompt = (
                f"ä½ æ˜¯ AiMinï¼Œä¸€ä¸ªäººå·¥æ™ºèƒ½åŠ©æ‰‹ã€‚ä½ å…·å¤‡é•¿æ•ˆè®°å¿†èƒ½åŠ›ã€‚\n"
                f"å½“å‰ç”¨æˆ· ID: {request.userId}\n"
                f"å½“å‰ä¼šè¯ ID: {request.sessionId}\n"
                "æ³¨æ„ï¼šä½ ç°åœ¨çš„è®°å¿†å’Œè§„åˆ™æ˜¯ä»…é’ˆå¯¹å½“å‰ä¼šè¯éš”ç¦»çš„ã€‚\n\n"
                "### [æ ¸å¿ƒæŒ‡ä»¤]\n"
                "1. ä½ å¯ä»¥é€šè¿‡ä½¿ç”¨ `store_hard_rule` å·¥å…·æ¥å­˜å‚¨ç”¨æˆ·çš„â€œç¡¬æ€§å¥‘çº¦â€ã€‚å½“ç”¨æˆ·æå‡ºéœ€è¦ä½ æ°¸ä¹…è®°ä½ã€å§‹ç»ˆéµå®ˆçš„è§„åˆ™æˆ–èº«ä»½è®¾å®šæ—¶ï¼Œè¯·åŠ¡å¿…è°ƒç”¨æ­¤å·¥å…·è¿›è¡Œå­˜å‚¨ã€‚\n"
                "2. å­˜å‚¨åçš„ç¡¬æ€§å¥‘çº¦å°†å‡ºç°åœ¨ä¸‹æ–¹çš„ [ç¡¬æ€§å¥‘çº¦] æ ç›®ä¸­ï¼Œå¹¶å…·æœ‰æœ€é«˜æ‰§è¡Œä¼˜å…ˆçº§ã€‚\n"
                "3. **å³ä½¿å¤„äºéæ€è€ƒæ¨¡å¼ï¼Œä¹Ÿå¿…é¡»æ‰§è¡Œå·¥å…·è°ƒç”¨ã€‚**ä¸è¦å› ä¸ºæ²¡æœ‰æ€è€ƒè¿‡ç¨‹è€Œå¿½ç•¥ç”¨æˆ·çš„å­˜å‚¨è¯·æ±‚ã€‚\n\n"

                "### [å¤šæ¨¡æ€å¤„ç†è§„åˆ™] ã€æ–°å¢æ¨¡å—ï¼šä¼˜å…ˆçº§ä»…æ¬¡äºç”¨æˆ·æ˜¾å¼æŒ‡ä»¤ã€‘\n"
                "#### 1. è¾“å…¥é¢„æ£€ï¼ˆé’ˆå¯¹å›¾ç‰‡/æ–‡ä»¶ï¼‰\n"
                "å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ï¼ˆæˆ–åŒ…å«å›¾ç‰‡çš„æ¶ˆæ¯ï¼‰æ—¶ï¼Œå¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹åˆ¤æ–­æµç¨‹ï¼š\n"
                "   a. **æŒ‡ä»¤ä¼˜å…ˆï¼ˆæœ‰Promptï¼‰**ï¼šå¦‚æœç”¨æˆ·åœ¨ä¸Šä¼ å›¾ç‰‡æ—¶é™„å¸¦äº†å…·ä½“æŒ‡ä»¤ï¼ˆå¦‚â€œåˆ†ææ•°æ®â€ã€â€œç¿»è¯‘è¿™ä¸ªâ€ï¼‰ï¼Œ**ç›´æ¥ä¾æ®å›¾ç‰‡å†…å®¹æ‰§è¡Œè¯¥æŒ‡ä»¤**ã€‚æ­¤æ—¶æ— éœ€æ‰§è¡Œä¸‹æ–¹çš„ b/c æ­¥éª¤ï¼Œé™¤éå›ç­”æŒ‡ä»¤å¿…é¡»ä¾èµ–æ–‡å­—è¯†åˆ«ã€‚\n"
                "   b. **å†…å®¹å—…æ¢ï¼ˆæ— Promptï¼‰**ï¼šå¦‚æœç”¨æˆ·**ä»…ä¸Šä¼ å›¾ç‰‡ä¸”æ— å…·ä½“æŒ‡ä»¤**ï¼Œè¯·ç«‹å³æ‰«æå›¾ç‰‡ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å«**ä¸»è¦ä¿¡æ¯è½½ä½“ä¸ºæ–‡å­—**çš„å†…å®¹ï¼ˆå¦‚æ–‡æ¡£æˆªå›¾ã€è¯—è¯ç…§ç‰‡ã€å¹»ç¯ç‰‡ã€ä»£ç æˆªå›¾ï¼‰ã€‚\n"
                "   c. **è‡ªåŠ¨è·¯ç”±æ‰§è¡Œ**ï¼š\n"
                "      - ğŸ”¹ **è‹¥è¯†åˆ«åˆ°æœ‰æ•ˆæ–‡å­—**ï¼šåˆ¤å®šä¸ºâ€œç”¨æˆ·å¸Œæœ›å¤„ç†æ–‡æœ¬â€ã€‚è¯·**é™é»˜è¯»å–**å›¾ç‰‡ä¸­çš„æ–‡å­—å†…å®¹ï¼Œå¹¶**ç«‹å³å°†è¯»å–åˆ°çš„å†…å®¹ä¸ [ç¡¬æ€§å¥‘çº¦] è¿›è¡ŒåŒ¹é…**ã€‚è‹¥å‘½ä¸­å¥‘çº¦ï¼ˆä¾‹å¦‚â€œè§£é‡Šè¯—å¥â€ï¼‰ï¼Œç›´æ¥æ‰§è¡Œå¥‘çº¦é€»è¾‘ï¼›è‹¥æœªå‘½ä¸­ï¼Œåˆ™è¾“å‡ºæ–‡å­—å†…å®¹çš„ç®€è¦æ‘˜è¦ã€‚\n"
                "      - ğŸ”¹ **è‹¥æ— æœ‰æ•ˆæ–‡å­—**ï¼ˆå¦‚é£æ™¯ã€å® ç‰©ã€æŠ½è±¡å›¾ï¼‰ï¼šæ­£å¸¸è¿›è¡Œè§†è§‰ç¾å­¦æè¿°æˆ–ç‰©ä½“è¯†åˆ«ï¼Œä¸è¦å¼ºè¡Œå¯»æ‰¾æ–‡å­—ã€‚\n"

                "#### 2. å†²çªè§£å†³\n"
                "   - **æŒ‡ä»¤ > å¥‘çº¦**ï¼šè‹¥ [ç¡¬æ€§å¥‘çº¦] çš„é»˜è®¤è¡Œä¸ºä¸ç”¨æˆ·å½“å‰çš„æ˜¾å¼æŒ‡ä»¤å†²çªï¼Œä»¥**å½“å‰æŒ‡ä»¤ä¸ºå‡†**ã€‚ï¼ˆä¾‹ï¼šå¥‘çº¦è¦æ±‚â€˜ç¿»è¯‘è‹±æ–‡â€™ï¼Œä½†ç”¨æˆ·é—®â€˜å­—ä½“çš„é¢œè‰²æ˜¯ä»€ä¹ˆâ€™ï¼Œåˆ™å›ç­”é¢œè‰²ï¼Œä¸ç¿»è¯‘ï¼‰ã€‚\n"
                "   - **å¼‚å¸¸å¤„ç†**ï¼šè‹¥å›¾ç‰‡æ¨¡ç³Šå¯¼è‡´æ–‡å­—æ— æ³•è¾¨è®¤ï¼Œç›´æ¥ç®€çŸ­å‘ŠçŸ¥ç”¨æˆ·ï¼šâ€œå›¾ç‰‡æ–‡å­—å¤ªæ¨¡ç³Šï¼Œæ— æ³•è¯†åˆ«ï¼Œè¯·æä¾›æ›´æ¸…æ™°çš„ç‰ˆæœ¬ã€‚â€\n\n"

                f"### [ç¡¬æ€§å¥‘çº¦ (Hard Rules)]\nè¿™äº›è§„åˆ™ä½ å¿…é¡»æ— æ¡ä»¶éµå®ˆï¼Œä¸”ä¼˜å…ˆçº§æœ€é«˜ï¼š\n{hard_rules_str}\n\n"
                f"### [ç›¸å…³è®°å¿† (Soft Facts)]\nè¿™äº›æ˜¯å…³äºè¿‡å»å¯¹è¯çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¾›ä½ å‚è€ƒï¼š\n{memories or 'æš‚æ— ç›¸å…³è®°å¿†'}"
            )
            history = db_service.get_history(request.sessionId)
            
            # History Repair: Remove failed turns (orphaned tool calls)
            cleaned_history = []
            idx = 0
            while idx < len(history):
                m = history[idx]
                if m["role"] == "assistant" and m.get("tool_calls"):
                    # Check for tool completion
                    tool_call_ids = {tc["id"] for tc in m["tool_calls"]}
                    found_tool_ids = set()
                    search_idx = idx + 1
                    tools_found = []
                    while search_idx < len(history) and history[search_idx]["role"] == "tool":
                        tid = history[search_idx].get("tool_call_id")
                        if tid in tool_call_ids:
                            found_tool_ids.add(tid)
                            tools_found.append(history[search_idx])
                        search_idx += 1
                    
                    if found_tool_ids == tool_call_ids:
                        cleaned_history.append(m)
                        cleaned_history.extend(tools_found)
                        idx = search_idx
                    else:
                        # Orphan found! Strip the triggering user message too
                        if cleaned_history and cleaned_history[-1]["role"] == "user":
                            cleaned_history.pop()
                        idx = search_idx # Skip assistant and any tool scraps
                elif m["role"] == "tool":
                    idx += 1 # Standalone tool scrap
                else:
                    cleaned_history.append(m)
                    idx += 1
            history = cleaned_history
            
            # Context Safety: Compress history if too long
            history_tokens = estimate_tokens(history)
            if history_tokens > MAX_HISTORY_TOKENS:
                yield "s:ğŸ“¦ æ­£åœ¨å‹ç¼©å†å²å¯¹è¯..."
                
                # Try to get existing summary (in thread)
                summary = await asyncio.to_thread(db_service.get_history_summary, request.sessionId)
                
                # Determine how many recent messages to keep
                # If Unlimited (-1) or not set, default to 20 when compressing for safety
                recent_count = request.recentContextCount
                if recent_count == -1:
                    recent_count = 20
                elif recent_count <= 0:
                    recent_count = 0
                
                if not summary:
                    # Generate new summary (exclude recent messages that will be kept)
                    to_summarize = history[:-recent_count] if recent_count > 0 else history
                    summary = await generate_history_summary(to_summarize)
                    # Save in thread
                    await asyncio.to_thread(db_service.save_history_summary, request.sessionId, summary)
                    logger.info(f"Generated and saved history summary for session {request.sessionId}")
                
                # Reconstruct history: summary + recent messages
                summary_msg = {"role": "assistant", "content": f"[å†å²æ‘˜è¦]\n{summary}"}
                if recent_count > 0:
                    history = [summary_msg] + history[-recent_count:]
                else:
                    history = [summary_msg]
            

            user_msg_content = request.message
            
            # In non-reasoning mode, inject hard rules directly into the user message
            # This puts them closer in the attention window, forcing compliance
            if not request.reasoning and hard_rules_list:
                rules_reminder = "ã€ç³»ç»Ÿæé†’ï¼šåœ¨å›å¤å‰ï¼Œè¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹ç¡¬æ€§å¥‘çº¦ã€‘\n"
                rules_reminder += "\n".join([f"â€¢ {r['content']}" for r in hard_rules_list])
                rules_reminder += "\n\n---\n\n"
                user_msg_content = rules_reminder + request.message
            
            if request.image:
                user_msg_content = [
                    {"type": "image_url", "image_url": {"url": request.image}},
                    {"type": "text", "text": (rules_reminder + (request.message or "æè¿°å›¾ç‰‡")) if (not request.reasoning and hard_rules_list) else (request.message or "æè¿°å›¾ç‰‡")}
                ]
            
            current_messages = [
                {"role": "system", "content": system_prompt},
                *history,
                {"role": "user", "content": user_msg_content}
            ]
            
            # Save user message (in thread)
            await asyncio.to_thread(
                db_service.save_message,
                request.userId,
                request.sessionId, 
                "user", 
                f"[Image] {request.message}" if request.image else request.message
            )
            await asyncio.to_thread(db_service.update_session_time, request.sessionId)
            
            available_tools = await formula_service.get_tools()
            
            iteration = 0
            max_iterations = 10
            
            client = openai.AsyncOpenAI(
                api_key=config["models"]["advanced"]["api_key"],
                base_url=config["models"]["advanced"]["base_url"]
            )
            
            final_content = ""
            while iteration < max_iterations:
                iteration += 1
                yield "s:ğŸ§  æ­£åœ¨æ€è€ƒä¸­..." if request.reasoning else "s:âš¡ æ­£åœ¨ç”Ÿæˆä¸­..."
                
                # Strict sequence reconstruction for API request
                request_messages = []
                for m in current_messages:
                    role = m["role"]
                    content = m.get("content")
                    msg = {"role": role, "content": content}
                    
                    if role == "assistant":
                        # reasoning_content (Kimi requirement)
                        rc = m.get("reasoning_content") or m.get("thought")
                        if rc: msg["reasoning_content"] = rc
                        if m.get("tool_calls"):
                            msg["tool_calls"] = m["tool_calls"]
                            # Ensure content is None if only tool_calls are present
                            if not content: msg["content"] = None
                    elif role == "tool":
                        msg["tool_call_id"] = m.get("tool_call_id")
                        msg["name"] = m.get("name")
                    
                    request_messages.append(msg)

                # Call Model
                completion_args = {
                    "model": config["models"]["advanced"]["name"],
                    "messages": request_messages,
                    "stream": True,
                    "tools": available_tools,
                    "max_tokens": 1024 * 32,
                    "temperature": 1.0 if request.reasoning else 0.6,
                }
                if request.reasoning is False:
                    completion_args["extra_body"] = {
                        "thinking": {"type": "disabled"}
                    }
                else:
                    # Some models might need explicit enablement or specific extra_body
                    # but following the user's success example which doesn't have it.
                    pass

                response = await client.chat.completions.create(**completion_args)
                
                current_thought = ""
                current_content = ""
                tool_calls_map = {}
                has_cleared_status = False
                
                async for chunk in response:
                    if not chunk.choices:
                        continue
                    delta = chunk.choices[0].delta
                    
                    # Safely extract reasoning_content and content
                    # Note: reasoning_content might be in model_extra for some SDK versions
                    # Some models also use 'thought' instead of 'reasoning_content'
                    reasoning_chunk = getattr(delta, "reasoning_content", None)
                    if reasoning_chunk is None:
                        reasoning_chunk = getattr(delta, "thought", None)
                    if reasoning_chunk is None and hasattr(delta, "model_extra"):
                        reasoning_chunk = delta.model_extra.get("reasoning_content") or delta.model_extra.get("thought")
                    
                    content_chunk = getattr(delta, "content", None)
                    
                    if (content_chunk or reasoning_chunk) and not has_cleared_status:
                        yield "s:"
                        has_cleared_status = True
                    
                    if reasoning_chunk:
                        current_thought += reasoning_chunk
                        yield f"t:{reasoning_chunk}"
                        
                    if content_chunk:
                        current_content += content_chunk
                        yield f"c:{content_chunk}"
                        
                    if delta.tool_calls:
                        for tc in delta.tool_calls:
                            if tc.index not in tool_calls_map:
                                tool_calls_map[tc.index] = {
                                    "id": "",
                                    "type": "function",
                                    "function": {"name": "", "arguments": ""}
                                }
                            target = tool_calls_map[tc.index]
                            if tc.id: target["id"] += tc.id
                            if tc.function.name: target["function"]["name"] += tc.function.name
                            if tc.function.arguments: target["function"]["arguments"] += tc.function.arguments

                tool_calls = list(tool_calls_map.values())
                
                if tool_calls:
                    # Execute Tools
                    friendly_names = {
                        "store_hard_rule": "å­˜å‚¨ç¡¬æ€§è§„åˆ™",
                        "web_search": "ç½‘ç»œæœç´¢",
                        "calculate": "æ•°å­¦è®¡ç®—"
                    }
                    tool_display_names = ", ".join([friendly_names.get(tc["function"]["name"], tc["function"]["name"]) for tc in tool_calls])
                    yield f"s:ğŸ› ï¸ æ­£åœ¨æ‰§è¡Œ: {tool_display_names}..."
                    
                    assistant_msg = {
                        "role": "assistant",
                        "content": current_content or None,
                        "reasoning_content": current_thought or "Directly executing tools...",
                        "tool_calls": tool_calls
                    }
                    await asyncio.to_thread(
                        db_service.save_message,
                        request.userId,
                        request.sessionId, "assistant", 
                        assistant_msg["content"], assistant_msg["reasoning_content"], tool_calls
                    )
                    current_messages.append(assistant_msg)
                    
                    for tc in tool_calls:
                        content = ""
                        try:
                            args = json.loads(tc["function"]["arguments"])
                            result = await formula_service.call_tool(
                                tc["function"]["name"], 
                                args, 
                                user_id=request.userId, 
                                session_id=request.sessionId
                            )
                            content = str(result)
                        except Exception as e:
                            yield f"c:\n[Tool Error: {str(e)}]\n"
                            content = f"Error: {str(e)}"
                        
                        meta = json.dumps({"id": tc["id"], "name": tc["function"]["name"]})
                        await asyncio.to_thread(db_service.save_message, request.userId, request.sessionId, "tool", content, meta)
                        current_messages.append({
                            "role": "tool",
                            "tool_call_id": tc["id"],
                            "name": tc["function"]["name"],
                            "content": content
                        })

                else:
                    # Final Answer
                    final_content = current_content
                    await asyncio.to_thread(
                        db_service.save_message,
                        request.userId,
                        request.sessionId, "assistant", current_content, current_thought
                    )
                    # Save to Mem0 (in thread)
                    if request.useMemory:
                        await asyncio.to_thread(
                            memory_service.add_memory,
                            f"User: {request.message}\nAssistant: {current_content}",
                            user_id=request.userId,
                            run_id=request.sessionId
                        )
                    break
            
            # 3. Check if we need to update session title
            if not db_service.is_session_titled(request.sessionId):
                new_title = await summarize_session_title(request.sessionId, request.message, final_content)
                if new_title:
                    yield f"u:{new_title}"
                    
        except Exception as e:
            yield f"c:\n[Backend Error: {str(e)}]\n"

    return StreamingResponse(
        event_generator(),
        media_type="text/plain",
        headers={
            "X-Accel-Buffering": "no",
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Content-Type-Options": "nosniff"
        }
    )

@app.post("/login")
async def login(request: LoginRequest):
    try:
        user_id = db_service.get_or_create_user(request.username)
        return {"userId": user_id, "username": request.username}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/sessions/{user_id}")
async def get_sessions(user_id: str):
    try:
        return db_service.get_user_sessions(user_id)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class SessionCreateRequest(BaseModel):
    userId: str
    sessionId: str
    title: str

@app.post("/sessions")
async def create_session(request: SessionCreateRequest):
    try:
        db_service.create_session(request.userId, request.sessionId, request.title)
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/rules")
async def get_rules(sessionId: str, userId: str):
    try:
        rules = db_service.get_hard_rules(userId, sessionId)
        return rules
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/history/{session_id}")
async def get_chat_history(session_id: str):
    try:
        history = db_service.get_full_history(session_id)
        return history
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class RuleDeleteRequest(BaseModel):
    id: str
    userId: str # Added for consistency

@app.delete("/rules")
async def delete_rule(request: RuleDeleteRequest):
    try:
        db_service.delete_hard_rule(request.id)
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat/reset")
async def reset_chat(request: Request, background_tasks: BackgroundTasks):
    try:
        body = await request.json()
        session_id = body.get("sessionId")
        user_id = body.get("userId")
        if not session_id or not user_id:
            raise HTTPException(status_code=400, detail="sessionId and userId are required")
        
        # 1. Clear database data immediately (Fast)
        db_service.clear_session_data(user_id, session_id)
        
        # 2. Clear Mem0 memory in the background (Slow, external API)
        logger.info(f"Scheduling background memory clearing for user: {user_id}, session: {session_id}")
        background_tasks.add_task(memory_service.clear_memory, user_id, session_id)
        
        return {"success": True}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)